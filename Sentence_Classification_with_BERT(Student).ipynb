{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWgujXmGqzIC"
   },
   "source": [
    "# Sentence Classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pr5PWYKGPi6R"
   },
   "source": [
    "In this lab we turn a pre-trained BERT model into a trainable Keras layer and apply it to the semeval 2017 task 4 subtask B that we tackled in lab 5. BERT (Bidirectional Embedding Representations from Transformers) is a new model for pre-training language representations that obtains state-of-the-art results on many NLP tasks. We demonstrate how to integrate BERT as a custom Keras layer to simplify model prototyping using huggingface. In this lab, you will learn: \n",
    "\n",
    "1) How to use the huggingface package.\n",
    "\n",
    "2) How to integrate BERT in our previous model. \n",
    "\n",
    "3) How to use the TPU from Colab. (Note: Running the BERT on the CPU would be very slow. Thus we recommend you to do this lab on Colab based on TPU provided by Google.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4spJ5PRhGJ1l"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import LSTM, RNN, Dropout, Input, LeakyReLU, Bidirectional,Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oimYsLssuSs"
   },
   "source": [
    "Before we start, we should install the huggingface transformer package. You can find the doc from its [website](https://huggingface.co/transformers/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AElpzsKFiZSo",
    "outputId": "1d7bd7e9-ef31-409e-d332-218499b5af2a"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebbamBD0xu5z"
   },
   "source": [
    "## Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbAMXQwqyVT8"
   },
   "source": [
    "In this lab we will use DistilBERT instead of BERT: DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, and runs 60% faster, while preserving over 95% of BERT’s performance as measured on the GLUE language understanding benchmark.\n",
    "\n",
    "It is easy to switch between DistilBERT and BERT using the huggingface transformer package. This huggingface package provides many pre-trained and pre-built models that are easy to use via a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-cUTxt02dQb"
   },
   "source": [
    "Before using DistilBERT or BERT, we need a tokenizer. Generally speaking, every BERT related model has its own tokenizer, trained for that model (see this week's lecture video on sub-word tokenization). \n",
    "We can get the DistilBERT tokenizer from **DistilBertTokenizer.from_pretrained** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "ee5e99cf86ff400ab103b571b4aa2920",
      "dd8d8690a9974af195362a3aef7a9372",
      "a547483168cb45378945e76740c1d694",
      "4d3ab8792e7e4897893f60ede2025fba",
      "4c930a67b01345cfad9ff4d85321e78e",
      "7b830fdfb0ac488998cc700b8d13ab46",
      "7dae803d2c74422a8755bf73010f211b",
      "ecba2d9e1c25481daaeac88b75e464eb",
      "549427d353534823a9564ef653693372",
      "fbc223df89b24278b09405993723d5ff",
      "98765a55fb724a68abc3fe16058859ef",
      "dc45481db4eb4882a12efd497e78e4e4",
      "9c89ab15ee2649e387259951e0f35c7e",
      "978af1c3bb724d7183cd78f48449bb98",
      "3fb86c89ecd94db0929188fa4994df88",
      "350e1f4e8dc54ba99d4ae3fdb39504e2",
      "90be74823b834ef8b9ef342838d3c27d",
      "e5baec179d8c4dbc84c2b93b747350e7",
      "c28285335d444c698a5995abfcfdc76e",
      "7c150b2f3458414aaf1703fdb0e94743",
      "a07cdccc664e4a9e91f0aebb34ab1e9c",
      "b258d258ae8b4ae59d901789bee3977f",
      "8132165178f34397bb48c7bc7e30b6bc",
      "f56794640fda4794876aa8113521b423"
     ]
    },
    "id": "hKj6Y_TydjeS",
    "outputId": "126f69c2-1af7-4a41-a4ed-142d1d770173"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, RobertaTokenizer \n",
    "import tqdm\n",
    "distil_bert = 'distilbert-base-uncased' # Pick any desired pre-trained model\n",
    "\n",
    "# Defining DistilBERT tokonizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n",
    "                                                max_length=128, pad_to_max_length=True)\n",
    "\n",
    "def tokenize(sentences, tokenizer, pad_length=128, pad_to_max_length=True ):\n",
    "    if type(sentences) == str:\n",
    "        inputs = tokenizer.encode_plus(sentences, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
    "                                             return_attention_mask=True, return_token_type_ids=True)\n",
    "        return np.asarray(inputs['input_ids'], dtype='int32'), np.asarray(inputs['attention_mask'], dtype='int32'), np.asarray(inputs['token_type_ids'], dtype='int32')\n",
    "    input_ids, input_masks, input_segments = [],[],[]\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
    "                                             return_attention_mask=True, return_token_type_ids=True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])        \n",
    "        \n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqMo6CPS3qJZ"
   },
   "source": [
    "Then we can use the tokenizer to tokenize the sentence. When working with word2vec and GloVe, we tokenized the sentence into words ourselves and then converted the tokens to GloVe word indices. But in BERT, we must use the BERT tokenizer: the tokens for BERT are different, and include whole words and sub-word tokens (see lecture video on sub-word tokenisation).\n",
    "\n",
    "For example, for the sentence: **This is a pretrained model.** our previous word-based tokenizer will generate the following tokens:\n",
    "\n",
    "**\"this\", \"is\", \"a\", \"pretrained\", \"model\", \".\"**\n",
    "\n",
    "Then you will find out that the word token \"pretrained\" is not in the GloVe word dictionary. Thus we can not assign a proper word vector for \"pretrained\".\n",
    "\n",
    "In BERT, the BERT tokenizer will separate the word \"pretrained\" into three sub-word tokens:\n",
    "\n",
    "**'pre', '##train', '##ed'**\n",
    "\n",
    "This way, BERT can use these three token vectors to represent the word \"pretrained\". Without the BERT tokenizer, it is hard to separate these unknown words properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRoKe2DKyi41",
    "outputId": "9fd00323-8789-4123-cfcd-fee58454991c"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer.tokenize(\"The capital of France is [MASK].\")\n",
    "print(inputs,'\\n')\n",
    "\n",
    "inputs = tokenizer.tokenize(\"This is a pretrained model.\")\n",
    "print(inputs,'\\n')\n",
    "\n",
    "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer)\n",
    "print(ids)\n",
    "print(masks,\"\\n\")\n",
    "\n",
    "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer, pad_to_max_length=False)\n",
    "print(ids)\n",
    "print(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6OuZAA8sbdg"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqvPQvgvPv1W"
   },
   "source": [
    "### Downloading and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EundMtGPpCdf"
   },
   "source": [
    "Similar to lab 5, we need to download and preprocess the data first. The data download code is consistent with lab 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyuSzkafqNca",
    "outputId": "69788bcc-deb3-4c72-819f-036f9f16a879"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def downloadfile(url):\n",
    "  rq = requests.get(url)\n",
    "  open(url.split('/')[-1], 'wb').write(rq.content)\n",
    "\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/downloaded/twitter-2016devtest-BD.tsv')\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/downloaded/twitter-2016dev-BD.tsv')\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/downloaded/twitter-2016test-BD.tsv')\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/downloaded/twitter-2016train-BD.tsv')\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/downloaded/twitter-2015test-BD.tsv')\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/downloaded/twitter-2015train-BD.tsv')\n",
    "\n",
    "downloadfile('https://raw.githubusercontent.com/cbaziotis/datastories-semeval2017-task4/master/dataset/Subtask_BD/gold/SemEval2017-task4-test.subtask-BD.english.txt')\n",
    "\n",
    "with open('twitter-2016dev-BD.tsv', 'r') as f:\n",
    "  dev_original = [l.strip().split('\\t') for l in f.readlines()]\n",
    "with open('SemEval2017-task4-test.subtask-BD.english.txt', 'r') as f:\n",
    "  test_original = [l.strip().split('\\t') for l in f.readlines()]\n",
    "train_original = []\n",
    "with open('twitter-2016train-BD.tsv', 'r') as f:\n",
    "  train_original = [l.strip().split('\\t') for l in f.readlines()]\n",
    "with open('twitter-2016test-BD.tsv', 'r') as f:\n",
    "  train_original.extend([l.strip().split('\\t') for l in f.readlines()])\n",
    "with open('twitter-2016devtest-BD.tsv', 'r') as f:\n",
    "  train_original.extend([l.strip().split('\\t') for l in f.readlines()])\n",
    "with open('twitter-2015test-BD.tsv', 'r') as f:\n",
    "  train_original.extend([l.strip().split('\\t') for l in f.readlines() if l.strip().split('\\t')[2] in ['negative','positive']])\n",
    "with open('twitter-2015train-BD.tsv', 'r') as f:\n",
    "  train_original.extend([l.strip().split('\\t') for l in f.readlines() if l.strip().split('\\t')[2] in ['negative','positive']])\n",
    "\n",
    "print(\"Training entries: {}\".format(len(train_original)))\n",
    "print(\"Development entries: {}\".format(len(dev_original)))\n",
    "print(\"Testing entries: {}\".format(len(test_original)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U4iCV9-rmay"
   },
   "source": [
    "We now can start playing around with the data, let’s first see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-gjWRAuqg5s",
    "outputId": "b8d8a87b-04ea-4754-8e46-b23886d1bc31"
   },
   "outputs": [],
   "source": [
    "print(\"ID \\t TOPIC \\t LABLE \\t TWEET_TEXT\")\n",
    "print(train_original[0])\n",
    "print(train_original[1])\n",
    "print(train_original[2])\n",
    "print(train_original[3])\n",
    "print(train_original[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvuu4KhStqei"
   },
   "source": [
    "According to the BERT tokenize function above, we can convert the tweet text and topic words to integers:\n",
    "\n",
    "(Note: as explained above, the BERT tokenize function is different from lab 5.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMCH1OoDrSNR",
    "outputId": "673e07f7-f361-42ae-93cf-3a1d8ce6c8c0"
   },
   "outputs": [],
   "source": [
    "# Please write your code to generate the following data\n",
    "# x_train_tweet_int\n",
    "# x_train_tweet_masks\n",
    "# x_train_topic_int\n",
    "# x_train_topic_masks\n",
    "\n",
    "# x_dev_tweet_int\n",
    "# x_dev_tweet_masks\n",
    "# x_dev_topic_int\n",
    "# x_dev_topic_masks\n",
    "\n",
    "# x_test_tweet_int\n",
    "# x_test_tweet_masks\n",
    "# x_test_topic_int\n",
    "# x_test_topic_masks\n",
    "\n",
    "\n",
    "# your code goes here\n",
    "\n",
    "\n",
    "# If use the previous tokenize function, you can get a print result like:\n",
    "assert len(x_train_topic_int) == len(train_original)\n",
    "assert len(x_train_topic_masks) == len(x_train_topic_int)\n",
    "assert len(x_test_topic_int) == len(test_original)\n",
    "assert len(x_test_topic_masks) == len(x_test_topic_int)\n",
    "print(\"x_dev_topic_int[0]:\")\n",
    "print(x_dev_topic_int[0])\n",
    "print(\"x_dev_topic_masks[0]:\")\n",
    "print(x_dev_topic_masks[0])\n",
    "print(\"x_dev_tweet_int[0]:\")\n",
    "print(x_dev_tweet_int[0])\n",
    "print(\"x_dev_tweet_masks[0]:\")\n",
    "print(x_dev_tweet_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IreFXgruZot"
   },
   "source": [
    "We use 1 to represent \"positive\" and 0 for \"negative\" and generate the \"y\" data similar to previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abIb7Fe5u3GQ",
    "outputId": "657c0fd2-ae45-46b2-9ed2-99d43b2e51dc"
   },
   "outputs": [],
   "source": [
    "def label2int(dataset):\n",
    "  y = []\n",
    "  for example in dataset:\n",
    "    if example[2].lower() == \"negative\":\n",
    "      y.append(0)\n",
    "    else:\n",
    "      y.append(1)\n",
    "  return y\n",
    "  \n",
    "y_train = label2int(train_original)\n",
    "y_dev = label2int(dev_original)\n",
    "y_test = label2int(test_original)\n",
    "y_train = np.array(y_train)\n",
    "y_dev = np.array(y_dev)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train[1])\n",
    "print(y_train[2])\n",
    "print(y_train[3])\n",
    "print(y_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txxIQPEdFSgY"
   },
   "source": [
    "We also generate these target labels using one hot encoding (This will be used in model 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohDm-E7k2w6c",
    "outputId": "befdb89c-06f1-44bc-c00d-736fbeff27cc"
   },
   "outputs": [],
   "source": [
    "def int2onehot(dataset):\n",
    "  y = []\n",
    "  for example in dataset:\n",
    "    if example:\n",
    "      y.append(np.array([0,1]))\n",
    "    else:\n",
    "      y.append(np.array([1,0]))\n",
    "  return np.array(y)\n",
    "y_train_onehot = int2onehot(y_train)\n",
    "y_dev_onehot = int2onehot(y_dev)\n",
    "y_test_onehot = int2onehot(y_test)\n",
    "\n",
    "print(y_train_onehot[0])\n",
    "print(y_train_onehot[1])\n",
    "print(y_train_onehot[2])\n",
    "print(y_train_onehot[3])\n",
    "print(y_train_onehot[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnnSuspvC5b"
   },
   "source": [
    "Now we have almost done the data preprocessing. Unlike the previous lab1-lab4, there are two distinct parts to the input x (tweet and topic - see lab 5) which we must input to the model. The easiest way is to input the tweet and topic as paired sentences into the model, concatenating them and separating them by the special BERT sentence-separator token [SEP] (available as tokenizer.sep_token). Then we can apply BERT directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKOiVVXQu-_I",
    "outputId": "4074f778-4672-4669-8e90-23b94fdc2e3b"
   },
   "outputs": [],
   "source": [
    "# Please write your code to combine the tweet and topic into the following varibles\n",
    "# x_train_int\n",
    "# x_train_masks\n",
    "# x_dev_int\n",
    "# x_dev_masks\n",
    "# x_test_int\n",
    "# x_test_masks\n",
    "\n",
    "# Tips: \n",
    "# 1) We can use the special token <SEP> to concatenate the tweets and topics.\n",
    "# 2) After combine them, make sure they are paded.\n",
    "\n",
    "\n",
    "\n",
    "# your code goes here\n",
    "\n",
    "\n",
    "\n",
    "# Don't forget the to use np.array function to wrap the ouput of pad_sequences function\n",
    "x_train_int_np = np.array(x_train_int)\n",
    "x_train_masks_np = np.array(x_train_masks)\n",
    "x_dev_int_np = np.array(x_dev_int)\n",
    "x_dev_masks_np = np.array(x_dev_masks)\n",
    "x_test_int_np = np.array(x_test_int)\n",
    "x_test_masks_np = np.array(x_test_masks)\n",
    "\n",
    "\n",
    "print(x_dev_int[0])\n",
    "print(x_dev_masks[0],'\\n')\n",
    "print(x_dev_int_np[0])\n",
    "print(x_dev_masks_np[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your report, show a few examples of your input, with text and topic included but separated by [SEP]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqvUGIwwGJqu"
   },
   "source": [
    "## Model 1: Prebuilt Sequence Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSxC41ln07im"
   },
   "source": [
    "The huggingface transformer package provides many prebuilt models. First, let us try a basic text classification model based on DistilBERT. This first method is the standard way BERT models are used for text classification: we use the embedding of the special [CLS] token at the beginning of the sequence, and put it through a simple classifier layer to make the decision. The TFDistilBertForSequenceClassification class takes care of that for us.\n",
    "\n",
    "The models with BERT are much bigger than our previous models. To run it faster, we can use TPU here. The detailed guideline about using TPU can be found from https://www.tensorflow.org/guide/tpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "707ec107d243469d9d7164ca6c804aaf",
      "1db50eb25e75468db59bba31c1fafad3",
      "2361780919364258a824ba6f904c873a",
      "76ff189b5d364160a6026f6b854a26f6",
      "b319f935e98e4c8e972cf76521f1eed3",
      "f4a988b553cb4680869779b0a49f71b3",
      "b083b306bfd943b4880f8a6ee1b211c2",
      "9e465b644a6845c583a01f97eac4ba83"
     ]
    },
    "id": "1gXFbb2cxBlw",
    "outputId": "ba3b9d2e-ad3c-4ca0-be16-00ba4f88853a"
   },
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "distil_bert = 'distilbert-base-uncased'\n",
    "\n",
    "config = DistilBertConfig(num_labels=2)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "def create_TFDistilBertForSequenceClassification():\n",
    "  transformer_model = TFDistilBertForSequenceClassification.from_pretrained(distil_bert, config = config)\n",
    "  input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "  input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
    "  X = transformer_model(input_ids, input_masks_ids)\n",
    "  return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
    "\n",
    "use_tpu = True\n",
    "if use_tpu:\n",
    "  # Create distribution strategy\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "  # Create model on TPU:\n",
    "  with strategy.scope():\n",
    "    model = create_TFDistilBertForSequenceClassification()\n",
    "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "  model = create_TFDistilBertForSequenceClassification()\n",
    "  model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CPFj0CMx9mw",
    "outputId": "2cdbbcff-35f4-42f3-b994-6eb54769e80d"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQQH5lE_33Vn",
    "outputId": "1003d24a-69f3-40a0-e5ad-ee7c92ef31d2"
   },
   "outputs": [],
   "source": [
    "history = model.fit([x_train_int_np,x_train_masks_np],\n",
    "                    y_train_onehot,\n",
    "                    epochs=30,\n",
    "                    batch_size=512,\n",
    "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev_onehot),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQcytuBdaWVp",
    "outputId": "bce4d8c1-0fa6-41fe-ce9f-75a9c3170a04"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate([x_test_int_np,x_test_masks_np], y_test_onehot)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your report, show the accuracy you achieve, and compare it to what you achieved in Lab 5. Is it better or worse, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdZ4nl08vp9A"
   },
   "source": [
    "\n",
    "## Model 2: Neural bag of words using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gyCwXFj_R5w"
   },
   "source": [
    "In this model, we take the NBOW classifier from lab 4 (model3-1) and integrate BERT. Instead of averaging over word2vec or GloVe word vectors, we are averaging over the embedding representations produced by BERT - but otherwise, the classifier is the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DStlnRQRf-4v"
   },
   "outputs": [],
   "source": [
    "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
    "    def call(self, x, mask=None):\n",
    "        if mask != None:\n",
    "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
    "        else:\n",
    "            return super().call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fTwmYDvNEyT"
   },
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "\n",
    "def get_BERT_layer():\n",
    "  distil_bert = 'distilbert-base-uncased'\n",
    "  config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "  config.output_hidden_states = False\n",
    "  return TFDistilBertModel.from_pretrained(distil_bert, config = config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VICS9rY8C7KH",
    "outputId": "3fa6c04d-3cd3-493b-d596-250a1c369dbb"
   },
   "outputs": [],
   "source": [
    "\n",
    "hdepth=16\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "EMBED_SIZE=100\n",
    "\n",
    "\n",
    "def create_bag_of_words_BERT():\n",
    "  input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "  input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32') \n",
    "\n",
    "  bert_embeddings = get_BERT_layer()\n",
    "  embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "\n",
    "  pooled_sent=GlobalAveragePooling1DMasked()(embedded_sent)\n",
    "  hidden_output=Dense(hdepth,input_shape=(MAX_SEQUENCE_LENGTH,EMBED_SIZE),activation='sigmoid',kernel_initializer='glorot_uniform')(pooled_sent) # Sigmoid\n",
    "  label=Dense(1,input_shape=(hdepth,),activation='sigmoid',kernel_initializer='glorot_uniform')(hidden_output)\n",
    "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
    "\n",
    "use_tpu = True\n",
    "if use_tpu:\n",
    "  # Create distribution strategy\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "  # Create model\n",
    "  with strategy.scope():\n",
    "    model2 = create_bag_of_words_BERT()\n",
    "    optimizer2 = keras.optimizers.Adam(lr=5e-5)\n",
    "    model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "  model2 = create_bag_of_words_BERT()\n",
    "  model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0SbsCsxF1zi",
    "outputId": "45cdf923-1e98-4a74-caea-b0eafbb3035c"
   },
   "outputs": [],
   "source": [
    "\n",
    "history = model2.fit([x_train_int_np,x_train_masks_np],\n",
    "                    y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=512,\n",
    "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rs0_vvG6UQtv",
    "outputId": "4085a287-2fdd-4313-d43f-06e1ec6c5d6f"
   },
   "outputs": [],
   "source": [
    "results = model2.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your report, show the accuracy you achieve, and compare it to what you achieved with Model 1 and in Lab 5. Is it better or worse, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awOphcCnhEwv"
   },
   "source": [
    "## Model 3: CNN or LSTM with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5codSzohQ_9"
   },
   "source": [
    "Please following model2 to finish a CNN or LSTM model with BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMiiWhW4hPRA"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your report, show the accuracy you achieve, and compare it to what you achieved with Model 1 and Model 2. Is it better or worse, and why?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_9_Sentence_Classification_with_BERT(Student).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1db50eb25e75468db59bba31c1fafad3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2361780919364258a824ba6f904c873a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4a988b553cb4680869779b0a49f71b3",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b319f935e98e4c8e972cf76521f1eed3",
      "value": 363423424
     }
    },
    "350e1f4e8dc54ba99d4ae3fdb39504e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fb86c89ecd94db0929188fa4994df88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c930a67b01345cfad9ff4d85321e78e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4d3ab8792e7e4897893f60ede2025fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecba2d9e1c25481daaeac88b75e464eb",
      "placeholder": "​",
      "style": "IPY_MODEL_7dae803d2c74422a8755bf73010f211b",
      "value": " 232k/232k [00:01&lt;00:00, 226kB/s]"
     }
    },
    "549427d353534823a9564ef653693372": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98765a55fb724a68abc3fe16058859ef",
       "IPY_MODEL_dc45481db4eb4882a12efd497e78e4e4"
      ],
      "layout": "IPY_MODEL_fbc223df89b24278b09405993723d5ff"
     }
    },
    "707ec107d243469d9d7164ca6c804aaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2361780919364258a824ba6f904c873a",
       "IPY_MODEL_76ff189b5d364160a6026f6b854a26f6"
      ],
      "layout": "IPY_MODEL_1db50eb25e75468db59bba31c1fafad3"
     }
    },
    "76ff189b5d364160a6026f6b854a26f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e465b644a6845c583a01f97eac4ba83",
      "placeholder": "​",
      "style": "IPY_MODEL_b083b306bfd943b4880f8a6ee1b211c2",
      "value": " 363M/363M [00:07&lt;00:00, 50.4MB/s]"
     }
    },
    "7b830fdfb0ac488998cc700b8d13ab46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c150b2f3458414aaf1703fdb0e94743": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f56794640fda4794876aa8113521b423",
      "placeholder": "​",
      "style": "IPY_MODEL_8132165178f34397bb48c7bc7e30b6bc",
      "value": " 466k/466k [00:00&lt;00:00, 2.52MB/s]"
     }
    },
    "7dae803d2c74422a8755bf73010f211b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8132165178f34397bb48c7bc7e30b6bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90be74823b834ef8b9ef342838d3c27d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c28285335d444c698a5995abfcfdc76e",
       "IPY_MODEL_7c150b2f3458414aaf1703fdb0e94743"
      ],
      "layout": "IPY_MODEL_e5baec179d8c4dbc84c2b93b747350e7"
     }
    },
    "978af1c3bb724d7183cd78f48449bb98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98765a55fb724a68abc3fe16058859ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_978af1c3bb724d7183cd78f48449bb98",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c89ab15ee2649e387259951e0f35c7e",
      "value": 28
     }
    },
    "9c89ab15ee2649e387259951e0f35c7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9e465b644a6845c583a01f97eac4ba83": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a07cdccc664e4a9e91f0aebb34ab1e9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a547483168cb45378945e76740c1d694": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b830fdfb0ac488998cc700b8d13ab46",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c930a67b01345cfad9ff4d85321e78e",
      "value": 231508
     }
    },
    "b083b306bfd943b4880f8a6ee1b211c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b258d258ae8b4ae59d901789bee3977f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b319f935e98e4c8e972cf76521f1eed3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c28285335d444c698a5995abfcfdc76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b258d258ae8b4ae59d901789bee3977f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a07cdccc664e4a9e91f0aebb34ab1e9c",
      "value": 466062
     }
    },
    "dc45481db4eb4882a12efd497e78e4e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_350e1f4e8dc54ba99d4ae3fdb39504e2",
      "placeholder": "​",
      "style": "IPY_MODEL_3fb86c89ecd94db0929188fa4994df88",
      "value": " 28.0/28.0 [00:00&lt;00:00, 96.7B/s]"
     }
    },
    "dd8d8690a9974af195362a3aef7a9372": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5baec179d8c4dbc84c2b93b747350e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecba2d9e1c25481daaeac88b75e464eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee5e99cf86ff400ab103b571b4aa2920": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a547483168cb45378945e76740c1d694",
       "IPY_MODEL_4d3ab8792e7e4897893f60ede2025fba"
      ],
      "layout": "IPY_MODEL_dd8d8690a9974af195362a3aef7a9372"
     }
    },
    "f4a988b553cb4680869779b0a49f71b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f56794640fda4794876aa8113521b423": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbc223df89b24278b09405993723d5ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
